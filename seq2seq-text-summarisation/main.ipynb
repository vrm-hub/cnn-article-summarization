{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "3c9QoZ1HH8xl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "val_df = pd.read_csv('validation.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "I84y-xHRff6h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "def tokenize_data(data):\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    input_texts, target_texts = data['article'].astype(str).tolist(), data['highlights'].astype(str).tolist()\n",
        "    input_encodings = tokenizer(input_texts, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
        "    target_encodings = tokenizer(target_texts, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
        "    return input_encodings, target_encodings\n",
        "\n",
        "train_inputs, train_targets = tokenize_data(train_df)\n",
        "val_inputs, val_targets = tokenize_data(val_df)\n",
        "test_inputs, test_targets = tokenize_data(test_df)\n",
        "\n",
        "torch.save(train_inputs, 'train_inputs.pt')\n",
        "torch.save(train_targets, 'train_targets.pt')\n",
        "torch.save(val_inputs, 'val_inputs.pt')\n",
        "torch.save(val_targets, 'val_targets.pt')\n",
        "torch.save(test_inputs, 'test_inputs.pt')\n",
        "torch.save(test_targets, 'test_targets.pt')"
      ],
      "metadata": {
        "id": "-WlxSPs0fnkq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "train_inputs = torch.load('train_inputs.pt')\n",
        "train_targets = torch.load('train_targets.pt')\n",
        "val_inputs = torch.load('val_inputs.pt')\n",
        "val_targets = torch.load('val_targets.pt')\n",
        "test_inputs = torch.load('test_inputs.pt')\n",
        "test_targets = torch.load('test_targets.pt')\n",
        "\n",
        "train_dataset = TensorDataset(train_inputs['input_ids'], train_targets['input_ids'])\n",
        "val_dataset = TensorDataset(val_inputs['input_ids'], val_targets['input_ids'])\n",
        "test_dataset = TensorDataset(test_inputs['input_ids'], test_targets['input_ids'])\n"
      ],
      "metadata": {
        "id": "K8ElxeurKjZN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim):\n",
        "        super(CustomEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        return output, hidden, cell\n",
        "\n",
        "class CustomDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, embedding_dim, hidden_dim):\n",
        "        super(CustomDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output)\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "013XUAuVfrUq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(tokenizer.get_vocab())\n",
        "output_dim = len(tokenizer.get_vocab())\n",
        "embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "\n",
        "encoder = CustomEncoder(input_dim, embedding_dim, hidden_dim)\n",
        "decoder = CustomDecoder(output_dim, embedding_dim, hidden_dim)\n",
        "\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "encoder.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    encoder_output, encoder_hidden, encoder_cell = encoder(train_inputs['input_ids'])\n",
        "\n",
        "torch.save(encoder_output, 'encoder_output.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TJpkxSjfclK",
        "outputId": "9ac80ce0-fb62-49b8-824b-1a98f5bbeb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(input_ids)\n",
        "        decoder_input = labels[:, :-1]\n",
        "        decoder_output, _, _ = decoder(decoder_input, encoder_hidden, encoder_cell)\n",
        "\n",
        "        loss = criterion(decoder_output.view(-1, decoder_output.shape[-1]), labels[:, 1:].contiguous().view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "total_val_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(input_ids)\n",
        "        decoder_input = labels[:, :-1]\n",
        "        decoder_output, _, _ = decoder(decoder_input, encoder_hidden, encoder_cell)\n",
        "\n",
        "        val_loss = criterion(decoder_output.view(-1, decoder_output.shape[-1]), labels[:, 1:].contiguous().view(-1))\n",
        "        total_val_loss += val_loss.item()\n",
        "\n",
        "print(f'Validation Loss: {total_val_loss / len(val_loader)}')\n"
      ],
      "metadata": {
        "id": "fQzrvyXJc3zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "total_test_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(input_ids)\n",
        "        decoder_input = labels[:, :-1]\n",
        "        decoder_output, _, _ = decoder(decoder_input, encoder_hidden, encoder_cell)\n",
        "\n",
        "        test_loss = criterion(decoder_output.view(-1, decoder_output.shape[-1]), labels[:, 1:].contiguous().view(-1))\n",
        "        total_test_loss += test_loss.item()\n",
        "\n",
        "print(f'Test Loss: {total_test_loss / len(test_loader)}')\n"
      ],
      "metadata": {
        "id": "bhfiGKDHgLAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}